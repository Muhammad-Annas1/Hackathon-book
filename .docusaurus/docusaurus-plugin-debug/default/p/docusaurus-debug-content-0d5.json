{"allContent":{"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/docs","tagsPath":"/docs/tags","editUrl":"https://github.com/Muhammad-Annas1/Hackathon-book/docs","isLast":true,"routePriority":-1,"sidebarFilePath":"D:\\Python\\hackathon-book\\docs\\sidebar.js","contentPath":"D:\\Python\\hackathon-book\\docs","docs":[{"id":"intro","title":"Introduction","description":"This book introduces you to the core concepts of modern robotics and AI systems.","source":"@site/docs/intro.md","sourceDirName":".","slug":"/intro","permalink":"/docs/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammad-Annas1/Hackathon-book/docs/intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Introduction"},"sidebar":"tutorialSidebar","next":{"title":"Chapter 1: Core ROS 2 Concepts","permalink":"/docs/module-1/chapter-1-core-concepts"}},{"id":"module-1/chapter-1-core-concepts","title":"Chapter 1: Core ROS 2 Concepts","description":"This chapter covers the fundamental concepts of the Robot Operating System (ROS) 2, the backbone of modern humanoid robotics.","source":"@site/docs/module-1/chapter-1-core-concepts.md","sourceDirName":"module-1","slug":"/module-1/chapter-1-core-concepts","permalink":"/docs/module-1/chapter-1-core-concepts","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammad-Annas1/Hackathon-book/docs/module-1/chapter-1-core-concepts.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Chapter 1: Core ROS 2 Concepts","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Introduction","permalink":"/docs/intro"},"next":{"title":"Chapter 1: Core ROS 2 Concepts","permalink":"/docs/module-1/chapter-1-core-concepts"}},{"id":"module-1/chapter-2-rclpy-control","title":"Chapter 2: Controlling Robots with rclpy","description":"rclpy is the official Python client library for ROS 2. It allows you to write ROS 2 nodes in Python and interact with the entire ROS 2 graph.","source":"@site/docs/module-1/chapter-2-rclpy-control.md","sourceDirName":"module-1","slug":"/module-1/chapter-2-rclpy-control","permalink":"/docs/module-1/chapter-2-rclpy-control","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammad-Annas1/Hackathon-book/docs/module-1/chapter-2-rclpy-control.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Chapter 2: Controlling Robots with rclpy","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Core ROS 2 Concepts","permalink":"/docs/module-1/chapter-1-core-concepts"},"next":{"title":"Chapter 3: URDF Fundamentals","permalink":"/docs/module-1/chapter-3-urdf-fundamentals"}},{"id":"module-1/chapter-3-urdf-fundamentals","title":"Chapter 3: URDF Fundamentals","description":"The Unified Robot Description Format (URDF) is an XML format used in ROS to describe all elements of a robot model. This includes the robot's links, joints, sensors, and their physical properties.","source":"@site/docs/module-1/chapter-3-urdf-fundamentals.md","sourceDirName":"module-1","slug":"/module-1/chapter-3-urdf-fundamentals","permalink":"/docs/module-1/chapter-3-urdf-fundamentals","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammad-Annas1/Hackathon-book/docs/module-1/chapter-3-urdf-fundamentals.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Chapter 3: URDF Fundamentals","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Controlling Robots with rclpy","permalink":"/docs/module-1/chapter-2-rclpy-control"},"next":{"title":"Chapter 4: Project - Simple Humanoid Joint Control","permalink":"/docs/module-1/chapter-4-joint-control-project"}},{"id":"module-1/chapter-4-joint-control-project","title":"Chapter 4: Project - Simple Humanoid Joint Control","description":"This project brings together all the concepts from the previous chapters to create a functional joint control pipeline for our humanoid robot.","source":"@site/docs/module-1/chapter-4-joint-control-project.md","sourceDirName":"module-1","slug":"/module-1/chapter-4-joint-control-project","permalink":"/docs/module-1/chapter-4-joint-control-project","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammad-Annas1/Hackathon-book/docs/module-1/chapter-4-joint-control-project.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"title":"Chapter 4: Project - Simple Humanoid Joint Control","sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: URDF Fundamentals","permalink":"/docs/module-1/chapter-3-urdf-fundamentals"},"next":{"title":"Chapter 1: Gazebo Physics","permalink":"/docs/module-2/chapter-1-gazebo-physics"}},{"id":"module-2/chapter-1-gazebo-physics","title":"Chapter 1: Gazebo Physics","description":"Gazebo is the classic simulator for ROS. It provides a robust physics engine and a rich set of plugins to simulate everything from simple sensors to complex humanoid dynamics.","source":"@site/docs/module-2/chapter-1-gazebo-physics.md","sourceDirName":"module-2","slug":"/module-2/chapter-1-gazebo-physics","permalink":"/docs/module-2/chapter-1-gazebo-physics","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammad-Annas1/Hackathon-book/docs/module-2/chapter-1-gazebo-physics.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Chapter 1: Gazebo Physics","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4: Project - Simple Humanoid Joint Control","permalink":"/docs/module-1/chapter-4-joint-control-project"},"next":{"title":"Chapter 1: Gazebo Physics","permalink":"/docs/module-2/chapter-1-gazebo-physics"}},{"id":"module-2/chapter-2-unity-digital-twin","title":"Chapter 2: Building a Unity Digital Twin","description":"While Gazebo is great for physics, Unity is the industry standard for high-fidelity visualization and human-robot interaction (HRI). A digital twin in Unity allows for realistic rendering and interactive experiences.","source":"@site/docs/module-2/chapter-2-unity-digital-twin.md","sourceDirName":"module-2","slug":"/module-2/chapter-2-unity-digital-twin","permalink":"/docs/module-2/chapter-2-unity-digital-twin","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammad-Annas1/Hackathon-book/docs/module-2/chapter-2-unity-digital-twin.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Chapter 2: Building a Unity Digital Twin","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Gazebo Physics","permalink":"/docs/module-2/chapter-1-gazebo-physics"},"next":{"title":"Chapter 3: Sensor Simulation in Gazebo & Unity","permalink":"/docs/module-2/chapter-3-sensor-simulation"}},{"id":"module-2/chapter-3-sensor-simulation","title":"Chapter 3: Sensor Simulation in Gazebo & Unity","description":"Sensors are the eyes and ears of a robot. Both Gazebo and Unity provide mechanisms to simulate realistic sensor data and stream it into ROS 2.","source":"@site/docs/module-2/chapter-3-sensor-simulation.md","sourceDirName":"module-2","slug":"/module-2/chapter-3-sensor-simulation","permalink":"/docs/module-2/chapter-3-sensor-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammad-Annas1/Hackathon-book/docs/module-2/chapter-3-sensor-simulation.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Chapter 3: Sensor Simulation in Gazebo & Unity","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Building a Unity Digital Twin","permalink":"/docs/module-2/chapter-2-unity-digital-twin"},"next":{"title":"Chapter 1: Isaac Sim Fundamentals","permalink":"/docs/module-3-isaac/chapter-1-isaac-sim-fundamentals"}},{"id":"module-3-isaac/chapter-1-isaac-sim-fundamentals","title":"Chapter 1: Isaac Sim Fundamentals","description":"NVIDIA Isaac Sim is a powerful robotics simulation platform built on NVIDIA Omniverse. It provides a photorealistic environment and highly accurate physics for developing and testing robots.","source":"@site/docs/module-3-isaac/chapter-1-isaac-sim-fundamentals.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/chapter-1-isaac-sim-fundamentals","permalink":"/docs/module-3-isaac/chapter-1-isaac-sim-fundamentals","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammad-Annas1/Hackathon-book/docs/module-3-isaac/chapter-1-isaac-sim-fundamentals.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Chapter 1: Isaac Sim Fundamentals","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Sensor Simulation in Gazebo & Unity","permalink":"/docs/module-2/chapter-3-sensor-simulation"},"next":{"title":"Chapter 1: Isaac Sim Fundamentals","permalink":"/docs/module-3-isaac/chapter-1-isaac-sim-fundamentals"}},{"id":"module-3-isaac/chapter-2-isaac-ros-vslam-perception","title":"Chapter 2: Isaac ROS VSLAM + Perception","description":"NVIDIA Isaac ROS is a collection of hardware-accelerated packages that allow ROS 2 developers to leverage the full power of NVIDIA GPUs for perception and navigation.","source":"@site/docs/module-3-isaac/chapter-2-isaac-ros-vslam-perception.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/chapter-2-isaac-ros-vslam-perception","permalink":"/docs/module-3-isaac/chapter-2-isaac-ros-vslam-perception","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammad-Annas1/Hackathon-book/docs/module-3-isaac/chapter-2-isaac-ros-vslam-perception.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Chapter 2: Isaac ROS VSLAM + Perception","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Isaac Sim Fundamentals","permalink":"/docs/module-3-isaac/chapter-1-isaac-sim-fundamentals"},"next":{"title":"Chapter 3: Nav2 Path Planning for Humanoids","permalink":"/docs/module-3-isaac/chapter-3-nav2-humanoid-planning"}},{"id":"module-3-isaac/chapter-3-nav2-humanoid-planning","title":"Chapter 3: Nav2 Path Planning for Humanoids","description":"Autonomous navigation is a core requirement for humanoid robots. While traditional robots use wheels, humanoids require a more complex approach to planning that accounts for stability and stepping.","source":"@site/docs/module-3-isaac/chapter-3-nav2-humanoid-planning.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/chapter-3-nav2-humanoid-planning","permalink":"/docs/module-3-isaac/chapter-3-nav2-humanoid-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammad-Annas1/Hackathon-book/docs/module-3-isaac/chapter-3-nav2-humanoid-planning.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Chapter 3: Nav2 Path Planning for Humanoids","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Isaac ROS VSLAM + Perception","permalink":"/docs/module-3-isaac/chapter-2-isaac-ros-vslam-perception"},"next":{"title":"Chapter 1: Voice-to-Action","permalink":"/docs/module-4-vla/chapter-1-voice-to-action"}},{"id":"module-3-isaac/chapter-4-isaac-sim-ros-workflow","title":"Chapter 4: Isaac Sim → Isaac ROS Workflow","description":"The true power of this stack lies in the seamless transition from simulation to real-world algorithms. This chapter explores the \"Sim-to-Algorithm\" pipeline.","source":"@site/docs/module-3-isaac/chapter-4-isaac-sim-ros-workflow.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/chapter-4-isaac-sim-ros-workflow","permalink":"/docs/module-3-isaac/chapter-4-isaac-sim-ros-workflow","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammad-Annas1/Hackathon-book/docs/module-3-isaac/chapter-4-isaac-sim-ros-workflow.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"title":"Chapter 4: Isaac Sim → Isaac ROS Workflow","sidebar_position":4}},{"id":"module-4-vla/chapter-1-voice-to-action","title":"Chapter 1: Voice-to-Action","description":"This chapter explores the fundamental concepts behind converting a spoken command into a robotic action. This voice-to-action pipeline is a cornerstone of modern human-robot interaction (HRI).","source":"@site/docs/module-4-vla/chapter-1-voice-to-action.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/chapter-1-voice-to-action","permalink":"/docs/module-4-vla/chapter-1-voice-to-action","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammad-Annas1/Hackathon-book/docs/module-4-vla/chapter-1-voice-to-action.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Chapter 1: Voice-to-Action","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Nav2 Path Planning for Humanoids","permalink":"/docs/module-3-isaac/chapter-3-nav2-humanoid-planning"},"next":{"title":"Chapter 1: Voice-to-Action","permalink":"/docs/module-4-vla/chapter-1-voice-to-action"}},{"id":"module-4-vla/chapter-2-cognitive-planning","title":"Chapter 2: Cognitive Planning with LLMs","description":"Cognitive planning is the \"brain\" of an autonomous robot. It involves taking a high-level, often abstract, goal and breaking it down into a concrete sequence of actions.","source":"@site/docs/module-4-vla/chapter-2-cognitive-planning.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/chapter-2-cognitive-planning","permalink":"/docs/module-4-vla/chapter-2-cognitive-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammad-Annas1/Hackathon-book/docs/module-4-vla/chapter-2-cognitive-planning.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Chapter 2: Cognitive Planning with LLMs","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Voice-to-Action","permalink":"/docs/module-4-vla/chapter-1-voice-to-action"},"next":{"title":"Chapter 3: Capstone - The VLA Workflow","permalink":"/docs/module-4-vla/chapter-3-capstone-overview"}},{"id":"module-4-vla/chapter-3-capstone-overview","title":"Chapter 3: Capstone - The VLA Workflow","description":"This chapter illustrates the full end-to-end system, where perception, reasoning, and action come together.","source":"@site/docs/module-4-vla/chapter-3-capstone-overview.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/chapter-3-capstone-overview","permalink":"/docs/module-4-vla/chapter-3-capstone-overview","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammad-Annas1/Hackathon-book/docs/module-4-vla/chapter-3-capstone-overview.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Chapter 3: Capstone - The VLA Workflow","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Cognitive Planning with LLMs","permalink":"/docs/module-4-vla/chapter-2-cognitive-planning"}}],"drafts":[],"sidebars":{"tutorialSidebar":[{"type":"doc","id":"intro"},{"type":"category","label":"Module 1: ROS 2 Fundamentals","link":{"type":"doc","id":"module-1/chapter-1-core-concepts"},"items":[{"type":"doc","id":"module-1/chapter-1-core-concepts"},{"type":"doc","id":"module-1/chapter-2-rclpy-control"},{"type":"doc","id":"module-1/chapter-3-urdf-fundamentals"},{"type":"doc","id":"module-1/chapter-4-joint-control-project"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: Digital Twin Simulation","link":{"type":"doc","id":"module-2/chapter-1-gazebo-physics"},"items":[{"type":"doc","id":"module-2/chapter-1-gazebo-physics"},{"type":"doc","id":"module-2/chapter-2-unity-digital-twin"},{"type":"doc","id":"module-2/chapter-3-sensor-simulation"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac)","link":{"type":"doc","id":"module-3-isaac/chapter-1-isaac-sim-fundamentals"},"items":[{"type":"doc","id":"module-3-isaac/chapter-1-isaac-sim-fundamentals"},{"type":"doc","id":"module-3-isaac/chapter-2-isaac-ros-vslam-perception"},{"type":"doc","id":"module-3-isaac/chapter-3-nav2-humanoid-planning"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: Vision-Language-Action","link":{"type":"doc","id":"module-4-vla/chapter-1-voice-to-action"},"items":[{"type":"doc","id":"module-4-vla/chapter-1-voice-to-action"},{"type":"doc","id":"module-4-vla/chapter-2-cognitive-planning"},{"type":"doc","id":"module-4-vla/chapter-3-capstone-overview"}],"collapsed":true,"collapsible":true}]}}]}},"docusaurus-plugin-content-pages":{"default":[{"type":"jsx","permalink":"/chatbot","source":"@site/src/pages/chatbot.js"},{"type":"jsx","permalink":"/","source":"@site/src/pages/index.js"}]},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}